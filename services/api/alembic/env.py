"""
Alembic environment configuration

This file is used by Alembic to configure database migrations.
It imports our SQLAlchemy models from the shared library.
"""
from logging.config import fileConfig
from sqlalchemy import engine_from_config, pool
from alembic import context
import sys
from pathlib import Path

# Add parent directory to path so we can import shared module
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))

# Import our models
from shared.database import Base
from shared.models import *  # noqa: F403, F401
import geoalchemy2  # noqa: F401 - Required for autogenerate to include geoalchemy2 types

# Alembic Config object
config = context.config

# Interpret the config file for Python logging
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# Add your model's MetaData object here for 'autogenerate' support
target_metadata = Base.metadata


def run_migrations_offline() -> None:
    """
    Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well. By skipping the Engine creation
    we don't even need a DBAPI to be available.
    """
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()


def process_revision_directives(context, revision, directives):
    """
    Ensure geoalchemy2 is imported in autogenerated migrations.

    We use PostGIS types in our models, so always include this import.
    """
    if directives[0].upgrade_ops is not None:
        script = directives[0]
        # Always add geoalchemy2 import since we use PostGIS types
        # script.imports is a set, so we add to it
        if script.imports is None:
            script.imports = {'import geoalchemy2'}
        else:
            script.imports.add('import geoalchemy2')


def include_object(object, name, type_, reflected, compare_to):
    """
    Filter objects to include in migrations.

    Only include our application tables. Exclude everything else:
    - Spatial indexes automatically created by GeoAlchemy2
    - PostGIS extension tables
    """
    # Exclude spatial index automatically created by GeoAlchemy2
    if type_ == "index" and name == "idx_cameras_location":
        return False

    # Only include our application tables - exclude all PostGIS tables
    if type_ == "table":
        # Whitelist our application tables
        app_tables = {
            'images', 'cameras', 'detections', 'classifications',
            'users', 'alert_rules', 'alert_logs', 'email_allowlist',
            'alembic_version'
        }
        # If it's not one of our tables, exclude it
        if name not in app_tables:
            return False

    return True


def run_migrations_online() -> None:
    """
    Run migrations in 'online' mode.

    In this scenario we need to create an Engine
    and associate a connection with the context.
    """
    # Get database URL from environment variable
    import os
    database_url = os.getenv('DATABASE_URL')
    if not database_url:
        raise ValueError("DATABASE_URL environment variable is not set")

    configuration = config.get_section(config.config_ini_section, {})
    configuration['sqlalchemy.url'] = database_url

    connectable = engine_from_config(
        configuration,
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        context.configure(
            connection=connection,
            target_metadata=target_metadata,
            process_revision_directives=process_revision_directives,
            include_object=include_object
        )

        with context.begin_transaction():
            context.run_migrations()


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()
